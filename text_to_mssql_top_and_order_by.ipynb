{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_num_order_by(query):\n",
    "    #import necessary libraries\n",
    "    from nltk import word_tokenize\n",
    "    import string\n",
    "    import re\n",
    "    import nltk\n",
    "    import pyodbc\n",
    "    import inflect\n",
    "    import pandas as pd\n",
    "    from textblob import TextBlob\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    #define function that will analyse the adjective or adverb selected as the top clause indicator, analyse its polarity and return\n",
    "    #the order by clause - either 'asc' or 'desc' or ''(in case no order by clause is identified)\n",
    "    def return_word_sent(word):\n",
    "        #the flow of the function is as below:\n",
    "        #1) obtain all synonym sets (as a list) for the top clause identifier using wordnet\n",
    "        #2) identity the polarity of each synonym in the above list to get a positive or negative score. The synonym is deemed positive if the positive score >negative score\n",
    "        #3) if more synonyms have a positive polarity than negative, then the top clause identifier is deemed positive.\n",
    "        #   this usually means the query is aimed at identifying the 'best performing product' or 'the vendor with the highest credit score' etc. Hence the order by clause will likely contain 'desc'\n",
    "        #   if the top clause identifier is deemed negative then the query is likely to identify 'the product with the lowest sales' etc. so the order by clause will likely contain 'asc'\n",
    "        \n",
    "        #additional libraries required for the function.\n",
    "        from nltk.corpus import sentiwordnet as swn\n",
    "        from nltk.corpus import wordnet as wn\n",
    "        #get list of synonym sets for the adjective/adverb selected as the top clause indicator.\n",
    "        synset_list=wn.synsets(word)\n",
    "        pos_score=0\n",
    "        neg_score=0\n",
    "        #identify if the top clause identifier has an overall positive or negative score, and return order by clause accordingly.\n",
    "        for synset in synset_list:\n",
    "            pos=swn.senti_synset(synset.name()).pos_score()\n",
    "            neg=swn.senti_synset(synset.name()).neg_score()\n",
    "            if(pos>neg):\n",
    "                pos_score+=1\n",
    "            else:\n",
    "                neg_score+=1\n",
    "        if(pos_score>neg_score):\n",
    "            return 'desc'\n",
    "        elif(neg_score>pos_score):\n",
    "            return 'asc'\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "    #remove any punctuations from the query\n",
    "    regex_comp = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    query=regex_comp.sub('',query)\n",
    "    #convert all letters to lower case\n",
    "    query=query.lower()\n",
    "    #tokenize the cleaned query\n",
    "    tok_query=word_tokenize(query)\n",
    "    #assign part of speech tags to the tokenized query\n",
    "    pos_query=nltk.pos_tag(tok_query)\n",
    "\n",
    "    #load tokenized query with pos tags to a dataframe\n",
    "    df=pd.DataFrame(pos_query,columns=['word','pos_tag'])\n",
    "    #remove any extra spaces from any words\n",
    "    df.word=df.word.str.strip()\n",
    "    #initialize pyodbc connector to connect to the adventure works database\n",
    "    cnxn = pyodbc.connect(\"Driver={SQL Server Native Client 11.0};\"\n",
    "                          \"Server=DESKTOP-FPH6QIE\\SQLEXPRESS;\"\n",
    "                          \"Database=AdventureWorks2012;\"\n",
    "                          \"Trusted_Connection=yes;\")\n",
    "\n",
    "    cursor = cnxn.cursor()\n",
    "    #obtain list of all view column names. These will be used to identify the column which the user query is pointing towards.\n",
    "    sql_query='select distinct column_name from INFORMATION_SCHEMA.columns where table_name like \\'v%\\' and column_name not like \\'businessentity%\\' order by column_name'\n",
    "    cursor.execute(sql_query)\n",
    "    rows=cursor.fetchall()\n",
    "    #load view colunms into a list\n",
    "    column_list=[]\n",
    "    for row in rows:\n",
    "        column_list.append(row[0])\n",
    "    #of all the nouns in the user query, identify which one matches most closely with the available column names.\n",
    "    #the noun with the highest match percentage will be treated as the column with the necessary data and hence the subject of the sentence\n",
    "    mat_ratio=0\n",
    "    max_match_noun=''\n",
    "    for noun_word in df.loc[df['pos_tag'].str.contains('NN'),'word']:\n",
    "        match_per=0\n",
    "        match_per_t=0\n",
    "        for column in column_list:\n",
    "            match_per_t=SequenceMatcher(None, noun_word, column).ratio()\n",
    "            if(match_per_t>match_per):\n",
    "                match_per=match_per_t\n",
    "        if(match_per>mat_ratio):\n",
    "            mat_ratio=match_per\n",
    "            max_match_noun=noun_word\n",
    "\n",
    "    df['row_num']=df.index.values\n",
    "    subject_row=int(df.loc[df['word']==max_match_noun,'row_num'])\n",
    "    #If there are multiple adjective/adverbs before the identified subject, then the word closest to the subject is picked.\n",
    "    df['dist_from_subj']=0\n",
    "    df.loc[(df['pos_tag']=='JJ')|(df['pos_tag']=='JJS')|(df['pos_tag']=='RB')|(df['pos_tag']=='RBS'),'dist_from_subj']=abs(df['row_num']-subject_row)\n",
    "    int_df=df.loc[df['dist_from_subj']!=0,['word','dist_from_subj']].sort_values('dist_from_subj')\n",
    "    int_df=int_df.reset_index()\n",
    "    top_cl_num=''\n",
    "    order_by_param=''\n",
    "    def_rows='5'\n",
    "    if(len(int_df)>0):\n",
    "        #pick the adjective/adverb closest to the identified subject as the top clause identifier.\n",
    "        top_cl_word=int_df.loc[0,'word']\n",
    "        order_by_param=''\n",
    "        top_cl_ident=df[['word','pos_tag']].copy()\n",
    "        #the top clause is accompanied by a number, which is usually either after the clause or before the clause:\n",
    "        # return top 10 highest selling products\n",
    "        # return 10 highest selling products\n",
    "        # the code below attempts to identify this number, if it is present in the query.\n",
    "        top_cl_ident['prev_index']=top_cl_ident.index.values-1\n",
    "        top_cl_ident['next_index']=top_cl_ident.index.values+1\n",
    "        top_cl_ident=pd.merge(top_cl_ident[['word','pos_tag','next_index','prev_index']],top_cl_ident[['word','pos_tag']],how='left',left_on='prev_index',right_index=True,suffixes=('','_prev'))\n",
    "        top_cl_ident=pd.merge(top_cl_ident[['word','pos_tag','next_index','word_prev','pos_tag_prev']],top_cl_ident[['word','pos_tag']],how='left',left_on='next_index',right_index=True,suffixes=('','_next'))\n",
    "        top_cl_ident=top_cl_ident.loc[(top_cl_ident['word']==top_cl_word),['word','pos_tag','word_prev','pos_tag_prev','word_next','pos_tag_next']]\n",
    "        top_cl_ident=top_cl_ident.reset_index()\n",
    "\n",
    "        noun_string=top_cl_ident.loc[0,'word']\n",
    "        for word in df.loc[df['pos_tag'].str.contains('NN'),'word']:\n",
    "            noun_string=noun_string+' '+word\n",
    "    \n",
    "        noun_str_polarity=TextBlob(noun_string).sentiment.polarity\n",
    "        if(noun_str_polarity >0):\n",
    "            order_by_param='desc'\n",
    "        elif(noun_str_polarity<0):\n",
    "            order_by_param='asc'\n",
    "        else:\n",
    "            order_by_param=return_word_sent(top_cl_ident['word'].values[0])\n",
    "    \n",
    "        if(top_cl_ident.loc[0,'pos_tag_prev']=='CD' and top_cl_ident.loc[0,'pos_tag_next']!='CD'):\n",
    "            top_cl_num=str(top_cl_ident.loc[0,'word_prev'])\n",
    "        elif(top_cl_ident.loc[0,'pos_tag_prev']!='CD' and top_cl_ident.loc[0,'pos_tag_next']=='CD'):\n",
    "            top_cl_num=str(top_cl_ident.loc[0,'word_next'])\n",
    "        else:\n",
    "            if(str(df.loc[(df['word']==max_match_noun),'pos_tag'].values[0])=='NN' or str(df.loc[(df['word']==max_match_noun),'pos_tag'].values[0])=='NNP'):\n",
    "                top_cl_num='1'\n",
    "            else:\n",
    "                top_cl_num=def_rows\n",
    "            \n",
    "    return(top_cl_num,order_by_param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
